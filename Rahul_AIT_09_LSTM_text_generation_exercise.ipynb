{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-jainr/deep-learning-sp23/blob/main/Rahul_AIT_09_LSTM_text_generation_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abUaqGlYI3w9"
      },
      "source": [
        "# Copyright\n",
        "<pre>\n",
        "You may use and modify this code for research and development purpuses.\n",
        "Using this code for educational purposes (self-paced or instructor led) without the permission of the author is prohibited.\n",
        "\n",
        "The following source was used when creating this code:\n",
        "https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
        "\n",
        "Copyright (c) 2023 Bálint Gyires-Tóth - All Rights Reserved\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQY4NwcOJv6A"
      },
      "source": [
        "## Character-based text generation with LSTMs\n",
        "This notebook shows how to train an LSTM with an arbitrary text corpus, and use the trained model to generate text.\n",
        "\n",
        "We start with the imports:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kbWkA6NIzoS"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import re, cgi"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCqyuI1fKbbD"
      },
      "source": [
        "# 1. Dataset acquisition and data preparation\n",
        "We can use any text, the larger text corpus is expected to result in better models. Here, we download a text file from gutenberg.org:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpCW9mcSJBXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71787e85-6ad4-4f9d-fcab-51728d7903e4"
      },
      "source": [
        "url_book=\"http://www.gutenberg.org/files/2151/2151-0.txt\"\n",
        "urlretrieve(url_book, 'book.txt')\n",
        "text = open(\"book.txt\", encoding='utf-8').read().lower()\n",
        "\n",
        "print('Number of characters in the text:', len(text))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of characters in the text: 486583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "3B2wBu050RZt",
        "outputId": "17101897-8869-435e-c071-e4fd6b049588"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffthe project gutenberg ebook of the works of edgar allan poe, volume 5, by edgar allan poe\\n\\nthis ebook is for the use of anyone anywhere in the united states and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. you may copy it, give it away or re-use it under the terms\\nof the project gutenberg license included with this ebook or online at\\nwww.gutenberg.org. if you are not located in the united states, you\\nwill have to check the laws of the country where you are located before\\nusing this ebook.\\n\\ntitle: the works of edgar allan poe, volume 5\\n\\nauthor: edgar allan poe\\n\\nrelease date: april, 2000 [ebook #2151]\\n[most recently updated: january 25, 2023]\\n\\nlanguage: english\\n\\ncharacter set encoding: utf-8\\n\\nproduced by: david widger\\nrevised by richard tonsing.\\n\\n*** start of the project gutenberg ebook the works of edgar allan poe, vol. 5 ***\\n\\n\\n\\n\\nthe works of edgar allan poe\\n\\nby edgar allan poe\\n\\nthe raven edition\\n\\nvolume v.\\n\\n\\n\\n\\ncontents\\n\\n\\n philosophy of furniture'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__ZCGV65JMqw"
      },
      "source": [
        "If the source is a html file, the html tags should be also stripped by uncommenting the following lines. Currently, we downloaded raw txt file, so we don't need to strip HTML tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tel5BBxTJI_b"
      },
      "source": [
        "# tag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n",
        "# no_tags = tag_re.sub('', text)\n",
        "# text = cgi.escape(no_tags) "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlENqpfgLHba"
      },
      "source": [
        "We calculate the unique characters of the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A6d__rGJRwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d1e2dd-731d-49ba-eede-00d6bb04227c"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('Unique characters of the book:', len(chars))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters of the book: 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c4R3TAY0frj",
        "outputId": "c2828e2c-8384-460c-fb77-bcc9fbf2c705"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '=',\n",
              " '?',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '{',\n",
              " '}',\n",
              " 'à',\n",
              " 'â',\n",
              " 'æ',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ö',\n",
              " 'ú',\n",
              " 'ü',\n",
              " 'œ',\n",
              " 'α',\n",
              " 'γ',\n",
              " 'δ',\n",
              " 'ε',\n",
              " 'η',\n",
              " 'ι',\n",
              " 'λ',\n",
              " 'ν',\n",
              " 'ξ',\n",
              " 'ο',\n",
              " 'π',\n",
              " 'ρ',\n",
              " 'ς',\n",
              " 'σ',\n",
              " 'τ',\n",
              " 'υ',\n",
              " 'χ',\n",
              " 'ῆ',\n",
              " 'ῦ',\n",
              " '—',\n",
              " '‘',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '•',\n",
              " '™',\n",
              " '\\ufeff']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StlPJfzaLPwl"
      },
      "source": [
        "Next, we create  character->index and index->character dictionaries for the one-hot encodings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ8Y0N9gJWOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862cf0dc-4353-4bad-a2f4-ccf4db2c2a12"
      },
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print (\"Indices to char dictionary:\", indices_char)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices to char dictionary: {0: '\\n', 1: ' ', 2: '!', 3: '#', 4: '$', 5: '%', 6: '&', 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '=', 27: '?', 28: '[', 29: ']', 30: '_', 31: 'a', 32: 'b', 33: 'c', 34: 'd', 35: 'e', 36: 'f', 37: 'g', 38: 'h', 39: 'i', 40: 'j', 41: 'k', 42: 'l', 43: 'm', 44: 'n', 45: 'o', 46: 'p', 47: 'q', 48: 'r', 49: 's', 50: 't', 51: 'u', 52: 'v', 53: 'w', 54: 'x', 55: 'y', 56: 'z', 57: '{', 58: '}', 59: 'à', 60: 'â', 61: 'æ', 62: 'è', 63: 'é', 64: 'ê', 65: 'ö', 66: 'ú', 67: 'ü', 68: 'œ', 69: 'α', 70: 'γ', 71: 'δ', 72: 'ε', 73: 'η', 74: 'ι', 75: 'λ', 76: 'ν', 77: 'ξ', 78: 'ο', 79: 'π', 80: 'ρ', 81: 'ς', 82: 'σ', 83: 'τ', 84: 'υ', 85: 'χ', 86: 'ῆ', 87: 'ῦ', 88: '—', 89: '‘', 90: '’', 91: '“', 92: '”', 93: '•', 94: '™', 95: '\\ufeff'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LocVYkLyLdMu"
      },
      "source": [
        "## 1.1. Creating 3D input data for the LSTM - exercise\n",
        "Split the text into 40 character long sequences with 10 characters overlap as input, and the next character as output. We will call these sequences as \"sentence\", however these are chunks of texts and not grammatically correct sentences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EUZeSgtJYYx"
      },
      "source": [
        "maxlen  = 40\n",
        "step    = 10   # the step size between two \"sentence\" is 10 characters\n",
        "sentences=  []\n",
        "next_chars = []\n",
        "# sentences  = [text[i:i+maxlen] for i in range(0, len(text), step)] # maxlen number of characters, with \"step\" overlap between two \"sentences\" \n",
        "# next_chars = [c for c in text[maxlen-step:]] # the next character\n",
        "\n",
        "# for sentence in sentences[:10]:\n",
        "#   print(sentence)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLkup7mdMGGE"
      },
      "source": [
        "Cut out sequences and the corresponding next characters from the corpus, where the sequence length is \"maxlen\", and the step size between two instances is \"step\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences[:2]):\n",
        "  for t, char in enumerate(sentence):\n",
        "    print(i, t, sentence, char)"
      ],
      "metadata": {
        "id": "zp_6AsAI5qZC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qisyd0qPJZO0"
      },
      "source": [
        "for i in range(0, len(text)-maxlen, step):\n",
        "    sentences.append(text[i:i+maxlen])\n",
        "    next_chars.append(text[maxlen])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2i1N-7XJbSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb98b369-549d-45fe-e1ab-1e69583a9ce1"
      },
      "source": [
        "print('Number of training samples:', len(sentences)) # it should be 48655"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 48655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU1UmI-hMvhr"
      },
      "source": [
        "Creating NumPy arrays with the correct shapes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH3vNrQrJcxy"
      },
      "source": [
        "X = np.zeros((len(sentences), maxlen, len(chars)))\n",
        "y = np.zeros((len(sentences), len(chars)))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKJobG0yM4D6"
      },
      "source": [
        "Introducing one-hot encodings to the NumPy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJKCmrCPJeWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ba8846-727a-46bc-e16b-fa4a5caf1041"
      },
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence): \n",
        "        X[i,t,char_indices[char]] = 1\n",
        "    y[i,char_indices[next_chars[i]]] = 1\n",
        "\n",
        "print (\"Shape of the input data:\", X.shape)\n",
        "print (\"Shape of the target data:\", y.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the input data: (48655, 40, 96)\n",
            "Shape of the target data: (48655, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmRQ_ptkNSTS"
      },
      "source": [
        "# 2. Model definition\n",
        "We define a simple LSTM model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMWAOmCDJjLM"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X.shape[-2], X.shape[-1])))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KUmJwjlNUjJ"
      },
      "source": [
        " Compiling the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jNSADEEJk9W"
      },
      "source": [
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWec07qYNW6J"
      },
      "source": [
        "# 3. Training and evaluation\n",
        "In this part we will perform training and evaluation together. As this is a generative model, it is not easy to evaluate it automatically. Now, we just generate some text with an input prompt during training the model. \n",
        "\n",
        "## 3.1. Sampling functions for evaluation\n",
        "\n",
        "Sampling the prediction, where the temperature's value controls the probability of selecting the highest value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhb7onnPJoCk"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds) \n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas), preds\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NceyMw2NxjM"
      },
      "source": [
        "Testing the sample function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un01jbmWJp-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6913f7b1-31da-452e-cc9b-bcf87a5191e6"
      },
      "source": [
        "fake_preds=[0.1, 0.2, 0.3, 0.15, 0.25]\n",
        "for temp in [0.1, 0.5, 1, 2, 4]:\n",
        "    print(fake_preds)\n",
        "    proba, preds = sample(fake_preds,temp)\n",
        "    print(preds)\n",
        "    print(proba)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[1.43537082e-05 1.46981972e-02 8.47572114e-01 8.27707142e-04\n",
            " 1.36887628e-01]\n",
            "2\n",
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[0.04444444 0.17777778 0.4        0.1        0.27777778]\n",
            "2\n",
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[0.1  0.2  0.3  0.15 0.25]\n",
            "2\n",
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[0.14384043 0.20342109 0.24913894 0.17616783 0.2274317 ]\n",
            "3\n",
            "[0.1, 0.2, 0.3, 0.15, 0.25]\n",
            "[0.17037527 0.20261148 0.22422646 0.18855123 0.21423556]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf0Y6ia0N7ee"
      },
      "source": [
        "## 3.2. Training and text generation\n",
        "The following code block does training for 10 epochs then generates text with different temperatures, and continiues training and and text generation again and again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRuiJTLEJr9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec9c112-e9b7-47a2-b6c3-c03c43b4ba33"
      },
      "source": [
        "start_index = random.randint(0, len(text) - maxlen - 1) # random starting point\n",
        "for iteration in range(1, 10):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(X, y, batch_size=128, epochs=10)\n",
        "    \n",
        "    for temp in [0.4, 1.0, 1.2]: # changing the \"temperature\"\n",
        "        print()\n",
        "        print('----- temperature:', temp)\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen] \n",
        "        generated += sentence\n",
        "        print('----- Generating with initial text: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(200): # we generate 400 characters\n",
        "            # creating the one-hot encoded input for the LSTM\n",
        "            x = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "            \tx[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x, verbose=0)[0] # forward pass\n",
        "            next_index,_ = sample(preds, temp) # sampling the predictions with \"temperature\"\n",
        "            next_char = indices_char[next_index] # converting the prediction to character\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char # we add the generated character to the input and delete the first character to keep it \"maxlen\" long\n",
        "\n",
        "            sys.stdout.write(next_char) # we print the character\n",
        "            sys.stdout.flush()\n",
        "       \n",
        "        preds=next_index=next_char=generated=sentence=\"\"\n",
        "\n",
        "        print()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 52s 128ms/step - loss: 0.0222\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 54s 141ms/step - loss: 9.2445e-07\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 53s 139ms/step - loss: 4.8577e-07\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 57s 151ms/step - loss: 3.2229e-07\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 67s 177ms/step - loss: 2.3842e-07\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 65s 170ms/step - loss: 2.3595e-07\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 58s 153ms/step - loss: 1.2376e-07\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 49s 128ms/step - loss: 1.1921e-07\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 1.1921e-07\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 46s 122ms/step - loss: 1.1921e-07\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 1.1921e-07\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 44s 117ms/step - loss: 1.1921e-07\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 3.5600e-08\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 2.6044e-09\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 8.8203e-10\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 5.3657e-10\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 48s 125ms/step - loss: 3.4791e-10\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 1.2005e-10\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 47s 122ms/step - loss: 4.6552e-11\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 49s 129ms/step - loss: 2.9401e-11\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 51s 134ms/step - loss: 7.3503e-12\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 52s 135ms/step - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 49s 130ms/step - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 49s 127ms/step - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 49s 128ms/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 49s 129ms/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 49s 129ms/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 50s 130ms/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 48s 126ms/step - loss: 0.0000e+00\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 48s 126ms/step - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 49s 128ms/step - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 48s 126ms/step - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 48s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 47s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 46s 120ms/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 48s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 48s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 48s 127ms/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 48s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 49s 130ms/step - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 48s 126ms/step - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 48s 127ms/step - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 48s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 50s 132ms/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 48s 127ms/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 48s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 47s 125ms/step - loss: 0.0000e+00\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 7\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 47s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 47s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 46s 122ms/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 46s 120ms/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 8\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 48s 125ms/step - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 46s 122ms/step - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 46s 120ms/step - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 46s 122ms/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 46s 122ms/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 9\n",
            "Epoch 1/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "381/381 [==============================] - 47s 124ms/step - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "381/381 [==============================] - 47s 123ms/step - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "381/381 [==============================] - 46s 120ms/step - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "381/381 [==============================] - 45s 118ms/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "381/381 [==============================] - 45s 118ms/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "381/381 [==============================] - 44s 116ms/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "381/381 [==============================] - 45s 117ms/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "381/381 [==============================] - 46s 121ms/step - loss: 0.0000e+00\n",
            "\n",
            "----- temperature: 0.4\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.0\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
            "\n",
            "----- temperature: 1.2\n",
            "----- Generating with initial text: \"e. i have not seen him,\n",
            "  but rumour spe\"\n",
            "e. i have not seen him,\n",
            "  but rumour spessssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xJjfgADOoPz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}