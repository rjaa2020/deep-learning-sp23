{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cW-EyI5Lxpqi"
   },
   "source": [
    "# Copyright\n",
    "\n",
    "<PRE>\n",
    "Copyright (c) 2023 Bálint Gyires-Tóth - All Rights Reserved\n",
    "You may use and modify this code for research and development purpuses.\n",
    "Using this code for educational purposes (self-paced or instructor led) without the permission of the author is prohibited.\n",
    "</PRE>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to deep learning-based classification and evaluation\n",
    "Today, we will dive into deep learning classifiers, with an ephasis on evaluation methods. \n",
    "\n",
    "\n",
    "## 1. Activation functions for classification\n",
    "First, lets have an intuation about the output of the final layers' activation functions. For binary and multilabel classification we use sigmoid, for multiclass classification softmax."
   ],
   "metadata": {
    "id": "3EX4cCa4WKJu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1/(1 + np.exp(-x))\n",
    "\n",
    "a = np.linspace(-5,5,40)\n",
    "print(a)\n",
    "print(sigmoid(a))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3olvG3yjbEj_",
    "outputId": "7fa5249a-6c6b-4967-cc3a-3a34c6a0ce76"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.         -4.74358974 -4.48717949 -4.23076923 -3.97435897 -3.71794872\n",
      " -3.46153846 -3.20512821 -2.94871795 -2.69230769 -2.43589744 -2.17948718\n",
      " -1.92307692 -1.66666667 -1.41025641 -1.15384615 -0.8974359  -0.64102564\n",
      " -0.38461538 -0.12820513  0.12820513  0.38461538  0.64102564  0.8974359\n",
      "  1.15384615  1.41025641  1.66666667  1.92307692  2.17948718  2.43589744\n",
      "  2.69230769  2.94871795  3.20512821  3.46153846  3.71794872  3.97435897\n",
      "  4.23076923  4.48717949  4.74358974  5.        ]\n",
      "[0.00669285 0.00863217 0.01112713 0.01433278 0.01844474 0.02370801\n",
      " 0.03042661 0.03897319 0.04979714 0.06342879 0.08047598 0.10160773\n",
      " 0.12751884 0.1588691  0.19619362 0.23978727 0.28957771 0.34501473\n",
      " 0.40501421 0.46799255 0.53200745 0.59498579 0.65498527 0.71042229\n",
      " 0.76021273 0.80380638 0.8411309  0.87248116 0.89839227 0.91952402\n",
      " 0.93657121 0.95020286 0.96102681 0.96957339 0.97629199 0.98155526\n",
      " 0.98566722 0.98887287 0.99136783 0.99330715]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def softmax(x):\n",
    "  return(np.exp(x)/np.exp(x).sum())\n",
    "\n",
    "pred1 = [100,10,1]\n",
    "pred2 = [20,10,1]\n",
    "pred3 = [2,1,1]\n",
    "pred4 = [-10,0,10]\n",
    "\n",
    "print(softmax(pred1), np.sum(pred1), np.sum(softmax(pred1)))\n",
    "print(softmax(pred2), np.sum(pred2), np.sum(softmax(pred2)))\n",
    "print(softmax(pred3), np.sum(pred3), np.sum(softmax(pred3)))\n",
    "print(softmax(pred4), np.sum(pred4), np.sum(softmax(pred4)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgEF-6tVbkBp",
    "outputId": "b51736a4-8907-4386-fa0f-e7bf6b1f2e6f"
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 8.19401262e-40 1.01122149e-43] 111 1.0\n",
      "[9.99954597e-01 4.53978684e-05 5.60254205e-09] 31 1.0\n",
      "[0.57611688 0.21194156 0.21194156] 4 1.0\n",
      "[2.06106005e-09 4.53978686e-05 9.99954600e-01] 0 0.9999999999999999\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Model training\n",
    "Let's train a simple MLP (Multi-Layer Perceptron) model on the CIFAR10 dataset and explore its capabilities."
   ],
   "metadata": {
    "id": "yY9fztIeWIKt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Dropout\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "metadata": {
    "id": "giRZKTjzX_7l"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ],
   "metadata": {
    "id": "bez7q0eiWQCK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "50227edc-e540-4af4-fe79-2acb85f91071"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "flattened_dim = np.prod(X_train.shape[1:])"
   ],
   "metadata": {
    "id": "hdoMyxHzuXZG"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# reshape 3D tensors to 2D tensors\n",
    "X_train = X_train.reshape(-1, flattened_dim)\n",
    "X_test = X_test.reshape(-1, flattened_dim)\n",
    "\n",
    "# it is in int8 format, the neural network requires float32\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")"
   ],
   "metadata": {
    "id": "vukOcBM0XzSj"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train, valid, test split\n",
    "train_ratio  = 0.8\n",
    "train_length = X_train.shape[0]\n",
    "train_split  = int(train_ratio*train_length)\n",
    "X_valid, Y_valid = X_train[train_split:], Y_train[train_split:]\n",
    "X_train, Y_train = X_train[:train_split], Y_train[:train_split]"
   ],
   "metadata": {
    "id": "mRwuWxxIxLgN"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# standardization\n",
    "mean = X_train.mean(axis=0)\n",
    "std  = X_train.std(axis=0)\n",
    "X_train = (X_train-mean)/std\n",
    "X_valid = (X_valid-mean)/std\n",
    "X_test  = (X_test-mean)/std"
   ],
   "metadata": {
    "id": "TSZbvWCBx8Ea"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# one-hot encoding\n",
    "nb_classes = len(np.unique(Y_train))\n",
    "Y_train = to_categorical(Y_train, nb_classes)\n",
    "Y_valid = to_categorical(Y_valid, nb_classes)\n",
    "Y_test  = to_categorical(Y_test, nb_classes)"
   ],
   "metadata": {
    "id": "i0LAO9cs8KEE"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# callbacks\n",
    "tb = TensorBoard(log_dir='logs', histogram_freq=0, write_graph=0)\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True, verbose=1, monitor='val_accuracy')"
   ],
   "metadata": {
    "id": "mqcsJfC5EXjt"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model definition with dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=HeNormal(), input_shape=(flattened_dim,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=HeNormal()))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# loss function and optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "7hZEGzj8GFwP"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# training\n",
    "network_history = model.fit(X_train, Y_train, \n",
    "                            validation_data=(X_valid,Y_valid),\n",
    "                            batch_size=128,                             \n",
    "                            epochs=400000, \n",
    "                            verbose=1, \n",
    "                            callbacks=[tb,es])"
   ],
   "metadata": {
    "id": "rarwKM1wGxMz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "01d8fbc4-b6b0-4a9e-954d-fb640831bb90"
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400000\n",
      "313/313 [==============================] - 24s 70ms/step - loss: 1.9345 - accuracy: 0.3745 - val_loss: 1.6159 - val_accuracy: 0.4294\n",
      "Epoch 2/400000\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 1.5353 - accuracy: 0.4559 - val_loss: 1.5280 - val_accuracy: 0.4628\n",
      "Epoch 3/400000\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.4369 - accuracy: 0.4908 - val_loss: 1.4765 - val_accuracy: 0.4816\n",
      "Epoch 4/400000\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 1.3646 - accuracy: 0.5141 - val_loss: 1.4698 - val_accuracy: 0.4857\n",
      "Epoch 5/400000\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 1.3104 - accuracy: 0.5361 - val_loss: 1.4485 - val_accuracy: 0.4943\n",
      "Epoch 6/400000\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.2613 - accuracy: 0.5530 - val_loss: 1.4468 - val_accuracy: 0.5002\n",
      "Epoch 7/400000\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 1.2206 - accuracy: 0.5687 - val_loss: 1.4347 - val_accuracy: 0.5126\n",
      "Epoch 8/400000\n",
      "313/313 [==============================] - 22s 72ms/step - loss: 1.1662 - accuracy: 0.5838 - val_loss: 1.4518 - val_accuracy: 0.5094\n",
      "Epoch 9/400000\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.1354 - accuracy: 0.5994 - val_loss: 1.4795 - val_accuracy: 0.5013\n",
      "Epoch 10/400000\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 1.0981 - accuracy: 0.6124 - val_loss: 1.4781 - val_accuracy: 0.5159\n",
      "Epoch 11/400000\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 1.0496 - accuracy: 0.6266 - val_loss: 1.4964 - val_accuracy: 0.5069\n",
      "Epoch 12/400000\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 1.0177 - accuracy: 0.6384 - val_loss: 1.5005 - val_accuracy: 0.5121\n",
      "Epoch 13/400000\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.9821 - accuracy: 0.6531 - val_loss: 1.5186 - val_accuracy: 0.5152\n",
      "Epoch 14/400000\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.9510 - accuracy: 0.6629 - val_loss: 1.5240 - val_accuracy: 0.5143\n",
      "Epoch 15/400000\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.9128 - accuracy: 0.6776 - val_loss: 1.5594 - val_accuracy: 0.5169\n",
      "Epoch 16/400000\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.8892 - accuracy: 0.6850 - val_loss: 1.5580 - val_accuracy: 0.5218\n",
      "Epoch 17/400000\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.8450 - accuracy: 0.6989 - val_loss: 1.5866 - val_accuracy: 0.5206\n",
      "Epoch 18/400000\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.8247 - accuracy: 0.7089 - val_loss: 1.6207 - val_accuracy: 0.5137\n",
      "Epoch 19/400000\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7933 - accuracy: 0.7196 - val_loss: 1.6468 - val_accuracy: 0.5180\n",
      "Epoch 20/400000\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7672 - accuracy: 0.7300 - val_loss: 1.6972 - val_accuracy: 0.5118\n",
      "Epoch 21/400000\n",
      "312/313 [============================>.] - ETA: 0s - loss: 0.7371 - accuracy: 0.7381Restoring model weights from the end of the best epoch: 16.\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.7371 - accuracy: 0.7380 - val_loss: 1.7240 - val_accuracy: 0.5208\n",
      "Epoch 21: early stopping\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Classification evaluation on test data\n",
    "Here, we will perform a detailed evaluation. Let's start by running an inference on the test data and get the predicted labels by argmax.\n"
   ],
   "metadata": {
    "id": "2FtKp-a2-A9m"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "Zd0DVDrOqoIe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# imports \n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score, recall_score, precision_score, f1_score, roc_curve, auc\n",
    "import seaborn as sns # for visualisation\n",
    "import matplotlib.pyplot as plt # for visualisation\n",
    "import matplotlib.colors as mcolors\n"
   ],
   "metadata": {
    "id": "k9T6OYQUiZpq"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "probas = model.predict(X_test)\n",
    "preds  = np.argmax(probas,axis=1)\n",
    "Y_test_dense = np.argmax(Y_test, axis=1) # get the original dense labels of the test data"
   ],
   "metadata": {
    "id": "I3_9wgDREUna",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "598a16fb-8635-431b-8405-6e0fe464b12b"
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1. Confusion matrix"
   ],
   "metadata": {
    "id": "Gcu-68Ynimdd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "conf"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01qU96O7rHJ0",
    "outputId": "3bc58c9e-80bd-4ac5-f4d7-d1eb20d83994"
   },
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_14152\\1353556874.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mconf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'conf' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "conf = confusion_matrix(Y_test_dense, preds)\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(conf, fmt='d', annot=True, vmin=1, vmax=200)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "RSQpDoNAiwAk",
    "outputId": "a3a8777d-0e8a-4df5-b80f-a1d0f0a3d8a6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Please, analyize the results - which classess are missclassified to other classes? See the [CIFAR10 class list](https://keras.io/api/datasets/cifar10/) on the Keras page. "
   ],
   "metadata": {
    "id": "ZSQTgJ_NjjXS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2. Accuracy, Precision, Recall, F1\n",
    "We can calculate these values based on the confusion matrix, or separately with function calls, or we can display all of them with one function."
   ],
   "metadata": {
    "id": "OWwykxwYlDrT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(accuracy_score(Y_test_dense, preds))\n",
    "print(precision_score(Y_test_dense, preds, average='micro'))\n",
    "print(precision_score(Y_test_dense, preds, average='macro'))\n",
    "print(precision_score(Y_test_dense, preds, average='weighted'))\n",
    "print(recall_score(Y_test_dense, preds, average='micro'))\n",
    "print(recall_score(Y_test_dense, preds, average='macro'))\n",
    "print(recall_score(Y_test_dense, preds, average='weighted'))\n",
    "print(f1_score(Y_test_dense, preds, average='micro'))\n",
    "print(f1_score(Y_test_dense, preds, average='macro'))\n",
    "print(f1_score(Y_test_dense, preds, average='weighted'))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DAxuEfXlcfM",
    "outputId": "cd32a1f7-f95a-4022-85d7-d0cbec2d9c98"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(np.argmax(Y_test,axis=1),preds))"
   ],
   "metadata": {
    "id": "XEEyU7exILqF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "439beea8-9ac9-4b75-bf59-b9ee99acf46f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(balanced_accuracy_score(np.argmax(Y_test,axis=1),preds))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psK2RPN6hmwQ",
    "outputId": "3c8248c8-fd0c-4738-c04c-3b3cb1fe1dd5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indeed, it is the same as the standard accuracy score, because the test dataset is perfectly balanced (1000 samples per each class). "
   ],
   "metadata": {
    "id": "seZTEFI-I5cZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3. ROC curve\n",
    "ROC curves can be applied to binary classification problems, thus, we have to adjust the predictions of each class into a binary case."
   ],
   "metadata": {
    "id": "uhkN7oPxpvDy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(np.unique(Y_test_dense))\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], probas[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=list(mcolors.TABLEAU_COLORS)[i], lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "# source: https://stackoverflow.com/questions/37017400/sklearn-metrics-roc-curve-for-multiclass-classification"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "ySfbg3rWpuqG",
    "outputId": "24a86e29-3297-42c4-c126-b595dccc274e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4. Prediction probabilities\n",
    "As a next step, it helps us to understand the capabilities of a classifier by analizing the histogram of the predicted probabilties. we wil show the idea for one class, however, it can be extended to all classes.\n",
    "\n",
    "We will evaluate the probabilities in a one-vs-rest manner, which means that we will select one class, and merge all other classess."
   ],
   "metadata": {
    "id": "ykCaHDPGs_F7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "selected_class=7\n",
    "Y_test_binary = Y_test_dense==selected_class\n",
    "probas_binary = np.concatenate((np.sum(np.delete(probas,selected_class,axis=1),axis=1).reshape(-1,1), probas[:,selected_class].reshape(-1,1)), axis=1)"
   ],
   "metadata": {
    "id": "A6ps4VT5tpc2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TP=(Y_test_dense == selected_class) & (preds == selected_class)\n",
    "TN=(Y_test_dense != selected_class) & (preds != selected_class)\n",
    "FP=(Y_test_dense != selected_class) & (preds == selected_class)\n",
    "FN=(Y_test_dense == selected_class) & (preds != selected_class)\n",
    "\n",
    "sns.histplot(probas_binary[TP,1], kde=False, bins=40)\n",
    "sns.histplot(probas_binary[FP,1], kde=False, bins=40, color='red')\n",
    "sns.histplot(probas_binary[FN,1], kde=False, bins=40, color='yellow')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "h0C_6YpCuhAC",
    "outputId": "baf04994-6c60-4d6a-c2cb-a5f3c5942c0b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "What does this figure mean? Think about it!\n",
    "\n",
    "We can also display the probability distribution of the target class of the TN cases:"
   ],
   "metadata": {
    "id": "xM3rh1s6xhW-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sns.histplot(probas_binary[TN,1], kde=False, bins=40, color='green')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "tb-UtOlVxqda",
    "outputId": "480fa555-71ad-4cba-9151-dcbcf9e0fb07"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5. Exercise\n",
    "Select and display 10-10 images that belong to class 7 and\n",
    "\n",
    "* 3.5.1. the same class was (correctly) predicted, with the highest probabilities \n",
    "* 3.5.2. a different class was (incorrectly) predicted, with the highest probabilities\n",
    "* 3.5.3. the same class was (correctly) predicted, with the lowest probabilities\n",
    "* 3.5.4. a different class was (incorrectly) predicted, with the lowest probabilities\n"
   ],
   "metadata": {
    "id": "xz-mqUQMyj7J"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "IVFiVWQgzKwo"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
